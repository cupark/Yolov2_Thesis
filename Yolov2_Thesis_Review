
==========================================================================================================================================================
  1. Yolov2의 등장 배경
     Yolov1의 한계: Yolov1은 다중 Object가 겹쳐있는 상황에 대한 예측이 어렵다. 또한 물체가 작을 수록 정확도가 떨어지며 새로운 바운딩 박스에 대한 예측이 
                    떨어진다. 첫째로 Object가 작아지는 경우에 예측이 떨어지는 이유는 Object가 작아질수록 IOU값의 차이도 근소하게 차이가 발생하게 되며 이에
                    따라서 Prediction Tensor가 아주 근소한 차이로 결정된다. 이러한 이유로 정확도와 예측이 떨어진다. 둘째로 Bounding Box 처리에서 Object의 
                    비율이 달라지면 Detection의 성능이 감소한다. 이는 Detection 모델의 공통적인 한계이다.
     개선사항 요약 : 
       1) Yolov2는 Yolov1의 단점인 mAP 성능을 향상 시켰다. 
       2) Recall과 Localization의 성능이 낮은 Yolov1의 구조적 한계를 극복함 
          한계1 -> 7x7x2의 Bounding Box로 된 구조가 객체를 찾는데 어려움
          한계2 -> Faster RCNN에서 생성하는 Bounding Box가 현저하게 적어서 Recall 성능이 발휘되지 않음
       3) mAP 
          극복1 -> BatchNormalization을 통하여 mAP를 2% 향상
          극복2 -> VGG16에서 DarkNet19를 사용하여 mAP를 4% 향상
          극복3 -> Anchor Box를 다중으로 사용할 때 mAP 성능이 향상됨을 확인(5로 제한)
          
==========================================================================================================================================================

==========================================================================================================================================================
  2. Yolov2 개선사항
     1) Batch Normalization 적용
        - Convolution Layer에 Batch Normalization을 적용하여 mAP를 2% 향상 
        - Batch Normalization: 
          (1) Gradient Descent: 역전파 알고리즘 이후 Loss값을 계산하여 가중치(w)를 조정한다. 일반적인 경우에 Graident를 업데이트 하기 위해서는 
                                학습데이터를 전부 넣어서 사용을 하는데 대용량읠 데이터를 한번에 처리하는 방식이기 때문에 시간적인 효율이 떨어진다.
                                이를 극복하고자 Batch 단위를 사용하여 학습을 진행한다. 
          (2) Batch: 전체 데이터셋을 일정한 크기의 나누는 단위를 의미한다.
          (3) Stochastic Gradient Descent: Gradient를 업데이트 하기 위하여 Batch만큼의 데이터를 사용하여 업데이트한다. 전체에 데이터에 대하여
                                           학습을 진행하는 것을 Epoch이라고 하고 Gradient를 구하는 단위는 Batch이다. 
          (4) Internal Covariant Shift: Batch 단위 학습 과정에서 발생하는 내부 입력데이터의 분포 공변현상이다. 
                                        입력의 Featrue Map에서 Conv + FC를 거친 데이터가 Batch 별로 분포가 달라지는 것이다. 
                                        이러한 상이 분포문제를 해결하기 위하여 Batch Normalization이 사용된다.
          (5) Batch Normalization: Batch 별 학습 과정에서 발생되는 Internal Covariant Shift를 방지하고자 사용되며, 각 Batch 별로 평균과 분산을 통하여
                                   정규화하는 단계를 추가한다. Batch의 단위 또는 Layer에 따라서 입력값에 대한 분포가 다르지만 정규화를 통하여
                                   Zero Mean Gaussian의 형태로 만든다. 따라서 평균은 0, 표준편차는 1로 데이터의 분포를 조정할 수 있다. 
                                   BN(x) = 감마(X - 뮤 Batch) / 시그마 Batch + 바이어스다.
                                   감마 - 가우시안, 시그마 - 합, 바이어스 - 스케일링     
          
        - mAP(Mean Average Precision): 인공신경망의 성능지표
          (1) 검출율과 정확도: Detect 알고리즘에서 검출율과 정확도의 의미를 알아햐한다. 예를 들어 첫번째 알고리즘은 검출율 99%에 오검출이 10%, 두번째 알고리즘은
                              검출율 50%에 오검출 0%일때 어떠한 알고리즘이 더 나은 알고리즘인가. 검출율이 높다고해서 좋은 알고리즘도 아니고 정확도가 낮다고하여
                              나쁜 알고리즘은 아니다. 
          (2) Precision-recall:  
                                     실제상황(Ground Truth)          예측결과(Predict Result)
                                                            Positive                        Negative  
                                        Positive        TP(True Positive)              FN(False Negative)
                                                            옳은 검출            검출되어야 할것들이 검출되지 않음
                                        Negative        FP(False Positive)             TN(True Negative)
                                                            틀린 검출          검출되지 않아야 할것들이 검출되지 않음
              1) IOU (Intersection Over Union): 
                 사용자가 설정한 Bounding Box와 Algorithm이 선택한 Bounding Box를 비교하여 박스의 옳고 그름을 판단한다.
                 IOU = 설정 Boundary와 예측 Boundary의 교집합 / 설정 Boundary와 예측 Boundary의 합집합
                 => 원본과 50%이상의 영역이 검출되었을때 TP반환, 미만인 경우 FP를 반환한다. 
              
              2) Precision: 정확도를 의미하며 TP / TP + FP이다. 검출된 대상이 얼마나 옳은 검출인가.
              
              3) Recall: 검출율을 의미하며 TP / TP + FN = TP / Ground Truth. 실제 옳은 검출중에 얼만큼 옳은 검출을 했는가.
              
              4) Precision-Recall: 정확도와 검출율은 반비례적 특성을 갖는다. 정확도가 올라감에 따라 검출율이 낮아지며 검출율이 올라감에 따라 정확도가 떨어진다.
                                   따라서 사용자는 Precision-recall 그래프를 통하여 성능변화를 살피어보고 결정해야한다.
                                   
          (3) Average Precision: 
              Precision-Recall 그래프를 통하여 얻어진 그래프 너비에 대한 정량적 비교를 위한 지표이다.
              1) 그래프 변환: 미세한 변화를 단순화 시키는 단조적 변환
              2) 넓이를 계산: X-Y 그래프에 그려진 PR 곡선에 대한 넓이를 구하여 AP로 산정한다. 
              :: mAP = Mean Average Precision으로 여러개의 분류 클래스에 대한 각각의 AP의 평균이다.
                 물체 검출 및 이미지 분류에 대한 알고리즘 평가지표로 사용된다.
                 
     2) High Resolution Classifier
        - Yolov1은 VGG16모델을 기반으로 224 x 224 크기의 해상도로 학습을 하고 448 x 448 크기의 이미지에 대하여 Object Detection을 수행하도록 설계되어
          성능이 떨어졌다. Yolov2는 VGG16모델 기반을 버리고 DarkNet19를 사용하여 학습전 이미지 분류 모델을 큰 해상도의 이미지에 대하여 Fine-tuning 단계를 거친다. 따라서 고해상도로 학습이 가능하고
          그 결과 mAP가 4% 정도 증가하였다.    
          Darknet19를 224 x 224의 해상도의 데이터로 학습시킨 뒤 448 x 448 이미지에 대하여 재 학습 시켜주어 Fine tunning을 진행한다.
          재학습시에는 Learning Rate를 작게 설정해준다.
        - DarkNet19
            Yolov1은 VGGNet 기반의 모델을 사용하였으나 Yolov2는 자체적으로 만든 CNN 모델을 사용하였다. 그 모델의 이름이 DarkNet19이다.
            1) Conv filter (3 x 3) x 32   -> 224 x 224 x 32   BatchNorm2d + LeakyReLU
               Maxpool     (2 x 2 -s2 )   -> 112 x 112 x 32
            2) Conv filter (3 x 3) x 64   -> 112 x 112 x 64   BatchNorm2d + LeakyReLU
               Maxpool     (2 x 2 -s2)    -> 56  x 56  x 64
            3) Conv filter (3 x 3) x 128  -> 56  x 56  x 128  BatchNorm2d + LeakyReLU
               Conv filter (1 x 1) x 64   -> 56  x 56  x 64   BatchNorm2d + LeakyReLU
               Conv filter (3 x 3) x 128  -> 56  x 56  x 128  BatchNorm2d + LeakyReLU
               Maxpool     (2 x 2 -s2)    -> 28  x 28  x 64
            4) Conv filter (3 x 3) x 256  -> 28  x 28  x 256  BatchNorm2d + LeakyReLU
               Conv filter (1 x 1) x 128  -> 28  x 28  x 128  BatchNorm2d + LeakyReLU
               Conv filter (3 x 3) x 256  -> 28  x 28  x 256  BatchNorm2d + LeakyReLU
               Maxpool     (2 x 2 -s2)    -> 14  x 14  x 256
            5) Conv filter (3 x 3) x 512  -> 14  x 14  x 512  BatchNorm2d + LeakyReLU
               Conv filter (1 x 1) x 256  -> 14  x 14  x 256  BatchNorm2d + LeakyReLU
               Conv filter (3 x 3) x 512  -> 14  x 14  x 512  BatchNorm2d + LeakyReLU
               Conv filter (1 x 1) x 256  -> 14  x 14  x 256  BatchNorm2d + LeakyReLU
               Conv filter (3 x 3) x 512  -> 14  x 14  x 512  BatchNorm2d + LeakyReLU
               Maxpool     (2 x 2 -s2)    ->  7  x  7  x 512
            6) Conv filter (3 x 3) x1024  ->  7  x  7  x 1024 BatchNorm2d + LeakyReLU
               Conv filter (1 x 1) x 512  ->  7  x  7  x 512  BatchNorm2d + LeakyReLU
               Conv filter (3 x 3) x1024  ->  7  x  7  x 1024 BatchNorm2d + LeakyReLU
               Conv filter (1 x 1) x 512  ->  7  x  7  x 512  BatchNorm2d + LeakyReLU
               Conv filter (3 x 3) x1024  ->  7  x  7  x 1024 BatchNorm2d + LeakyReLU
            7) Conv filter (1 x 1) x1000  ->  7  x  7  x 1000   
               AvgPool
               Softmax
             
          
     3) Convolutional With Anchor Boxes
        - Yolov1에서는 최종 Fully Connected Layer단에서 파생된 정보를 통하여 바운딩 박스를 예측한다. Yolov2는 이와 다르게 Fully Convolutional Network를 
         사용함으로써 예측한다. 더하여 Bounding Box의 개념에 대한 좌표 예측에서 Anchor Box로 크기와 비율에 대한 예측으로 변경하였다. 
         Anchor Box를 사용하므로써 사전에 정의된 크기와 비율이 결정되어 있는 박스로 Offset을 통하여 예측한다. 이러한 점은 학습이 간단해지는 장점이 있다.
     
     4) Dimension Cluster
        - Anchor Box를 수정하면서 바운딩 박스를 예측한다. 따라서 바운딩 박스들은 최적의 앵커박스를 찾는다. 클러스터링 갯수 k를 늘릴수록 클러스터링의 결과와
          라벨의 IOU는 커져 Recall(TP / TP + FN 검출되어야 되는 모든 상황에서 옳은 검출이 얼마나 됐는가.)이 상승한다. 따라서 k값과 결과값은 비례하지만 
          속도가 느려져 k = 5로 한정한다. 
          : TP = 옳은 검출, FN = 검출되야 할 것들이 검출되지 않음 
        
     5) Direct Location Prediction 
        - 앵커박스에 따라 5차원의 벡터로 구성된 바운딩박스를 예측한다. 경계박스가 그리드 셀에서 벗어나지 않도록 제약을 둔다.
          Yolov1에서 어느 Grid cell에 중심점이 있는지 확인했다면 Yolov2는 Left top 으로 부터의 offset이 얼만큼인지 예측한다. 
          
     6) Fine Grained Features
        - Yolov2의 출력되는 Feature Map의 크기는 13 x 13이다. 이는 작은 물체를 Detecting할 때 검출이 약하다는 단점이 생긴다. 
          이를 해결하기 위하여 상위단 Layer 중 26 x 26 사이즈의  Feature Map을 4등분한 뒤 하위 단 13 x 13 Feature Map에 이어 붙인다. 
          이러한 방법을 Fine-Grained Features라고 하며 이 방식을 통하여 작은 물체에 대한 객체 검출 성능을 확보한다. 
          
     7) Multi Scale Trainning
        - Yolov2는 작은 물체에 대해서 Detection을 수행하기 위하여 여러 스케일의 이미지를 학습하도록 한다. 
          Epoch의 10단위마다 32pixel씩 입력 이미지의 해상도를 올려가며 학습을 진행하고 이에 따라 다양한 크기의 입력에도 높은 예측 성능을 발휘한다.
          
     8) Summary
        - Yolov1 : VGG16, Fully Connected Layer, Bounding Box 
          - Bounding Box: x, y, w, h, c, x, y, w, h, c, pc 20 
            :: 7x7 - B x 5 + C = 30
        - Yolov2 : DarkNet19, Fully Convolutional Network, Anchor Box, Fine Grained Features
          - Anchor Box: x, y, w, h, c, pc, x, y, w, h, c, pc, .... , x, y, w, h, c, pc 
            :: 13x13 - B x (5 + C) = 125
         
        
          
          
             
             
             
         
          
==========================================================================================================================================================

==========================================================================================================================================================

==========================================================================================================================================================



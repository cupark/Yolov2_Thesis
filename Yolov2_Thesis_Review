
==========================================================================================================================================================
  1. Yolov2의 등장 배경
     Yolov1의 한계: Yolov1은 다중 Object가 겹쳐있는 상황에 대한 예측이 어렵다. 또한 물체가 작을 수록 정확도가 떨어지며 새로운 바운딩 박스에 대한 예측이 
                    떨어진다. 첫째로 Object가 작아지는 경우에 예측이 떨어지는 이유는 Object가 작아질수록 IOU값의 차이도 근소하게 차이가 발생하게 되며 이에
                    따라서 Prediction Tensor가 아주 근소한 차이로 결정된다. 이러한 이유로 정확도와 예측이 떨어진다. 둘째로 Bounding Box 처리에서 Object의 
                    비율이 달라지면 Detection의 성능이 감소한다. 이는 Detection 모델의 공통적인 한계이다.
==========================================================================================================================================================

==========================================================================================================================================================
  2. Yolov2 개선사항
     1) Batch Normalization 적용
        - Convolution Layer에 Batch Normalization을 적용하여 mAP를 2% 향상 
        - Batch Normalization: 
          (1) Gradient Descent: 역전파 알고리즘 이후 Loss값을 계산하여 가중치(w)를 조정한다. 일반적인 경우에 Graident를 업데이트 하기 위해서는 
                                학습데이터를 전부 넣어서 사용을 하는데 대용량읠 데이터를 한번에 처리하는 방식이기 때문에 시간적인 효율이 떨어진다.
                                이를 극복하고자 Batch 단위를 사용하여 학습을 진행한다. 
          (2) Batch: 전체 데이터셋을 일정한 크기의 나누는 단위를 의미한다.
          (3) Stochastic Gradient Descent: Gradient를 업데이트 하기 위하여 Batch만큼의 데이터를 사용하여 업데이트한다. 전체에 데이터에 대하여
                                           학습을 진행하는 것을 Epoch이라고 하고 Gradient를 구하는 단위는 Batch이다. 
          (4) Internal Covariant Shift: Batch 단위 학습 과정에서 발생하는 내부 입력데이터의 분포 공변현상이다. 
                                        입력의 Featrue Map에서 Conv + FC를 거친 데이터가 Batch 별로 분포가 달라지는 것이다. 
                                        이러한 상이 분포문제를 해결하기 위하여 Batch Normalization이 사용된다.
          (5) Batch Normalization: Batch 별 학습 과정에서 발생되는 Internal Covariant Shift를 방지하고자 사용되며, 각 Batch 별로 평균과 분산을 통하여
                                   정규화하는 단계를 추가한다. Batch의 단위 또는 Layer에 따라서 입력값에 대한 분포가 다르지만 정규화를 통하여
                                   Zero Mean Gaussian의 형태로 만든다. 따라서 평균은 0, 표준편차는 1로 데이터의 분포를 조정할 수 있다. 
                                   BN(x) = 감마(X - 뮤 Batch) / 시그마 Batch + 바이어스다.
                                   감마 - 가우시안, 시그마 - 합, 바이어스 - 스케일링
                                   
          
          
        - mAP(Mean Average Precision): 인공신경망의 성능지표
          (1) 검출율과 정확도: Detect 알고리즘에서 검출율과 정확도의 의미를 알아햐한다. 예를 들어 첫번째 알고리즘은 검출율 99%에 오검출이 10%, 두번째 알고리즘은
                              검출율 50%에 오검출 0%일때 어떠한 알고리즘이 더 나은 알고리즘인가. 검출율이 높다고해서 좋은 알고리즘도 아니고 정확도가 낮다고하여
                              나쁜 알고리즘은 아니다. 
          (2) Precision-recall:  
                                     실제상황(Ground Truth)          예측결과(Predict Result)
                                                            Positive                        Negative  
                                        Positive        TP(True Positive)              FN(False Negative)
                                                            옳은 검출            검출되어야 할것들이 검출되지 않음
                                        Negative        FP(False Positive)             TN(True Negative)
                                                            틀린 검출          검출되지 않아야 할것들이 검출되지 않음
              1) IOU (Intersection Over Union): 
                 사용자가 설정한 Bounding Box와 Algorithm이 선택한 Bounding Box를 비교하여 박스의 옳고 그름을 판단한다.
                 IOU = 설정 Boundary와 예측 Boundary의 교집합 / 설정 Boundary와 예측 Boundary의 합집합
                 => 원본과 50%이상의 영역이 검출되었을때 TP반환, 미만인 경우 FP를 반환한다. 
              
              2) Precision: 정확도를 의미하며 TP / TP + FP이다. 검출된 대상이 얼마나 옳은 검출인가.
              
              3) Recall: 검출율을 의미하며 TP / TP + FN = TP / Ground Truth. 실제 옳은 검출중에 얼만큼 옳은 검출을 했는가.
              
              4) Precision-Recall: 정확도와 검출율은 반비례적 특성을 갖는다. 정확도가 올라감에 따라 검출율이 낮아지며 검출율이 올라감에 따라 정확도가 떨어진다.
                                   따라서 사용자는 Precision-recall 그래프를 통하여 성능변화를 살피어보고 결정해야한다.
                                   
          (3) Average Precision: 
              Precision-Recall 그래프를 통하여 얻어진 그래프 너비에 대한 정량적 비교를 위한 지표이다.
              1) 그래프 변환: 미세한 변화를 단순화 시키는 단조적 변환
              2) 넓이를 계산: X-Y 그래프에 그려진 PR 곡선에 대한 넓이를 구하여 AP로 산정한다. 
              :: mAP = Mean Average Precision으로 여러개의 분류 클래스에 대한 각각의 AP의 평균이다.
                 물체 검출 및 이미지 분류에 대한 알고리즘 평가지표로 사용된다.
          
==========================================================================================================================================================

==========================================================================================================================================================

==========================================================================================================================================================


